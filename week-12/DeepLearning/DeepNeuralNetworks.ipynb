{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting Off\n",
    "\n",
    "How does sklearn utilize numpy?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to build a Deep Neural Network with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building steps:\n",
    "\n",
    "1. Specify Architecture\n",
    "\n",
    "2. Compile\n",
    "\n",
    "3. Fit \n",
    "\n",
    "4. Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify the architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T19:04:13.287465Z",
     "start_time": "2020-01-03T19:04:13.261043Z"
    }
   },
   "outputs": [],
   "source": [
    "#instantiate the model\n",
    "model = Sequential()\n",
    "#create a hidden layer and input layer at the same time\n",
    "model.add(Dense(32, activation='relu', input_shape = (n_cols,))) #input shape is adding a new column\n",
    "#add one hidden layer\n",
    "model.add(Dense(32, activation='relu'))\n",
    "#add the final layer\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compiling a model \n",
    "\n",
    "- Specify the optimizer\n",
    "    - Many options and mathematically complex\n",
    "    - “Adam” is usually a good choice \n",
    "- Loss function\n",
    "    - “mean_squared_error” common for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T19:04:14.141334Z",
     "start_time": "2020-01-03T19:04:14.124336Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='mean_squared_error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting a model\n",
    "\n",
    "- Applying backpropagation and gradient descent with your data to update the weights\n",
    "- Scaling data before fi!ing can ease optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T19:04:14.719800Z",
     "start_time": "2020-01-03T19:04:14.700041Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train neural network\n",
    "model.fit(features, # Features\n",
    "                      target, # Target\n",
    "                      epochs=15, # Number of epochs\n",
    "                      verbose=2, # Some output\n",
    "                      batch_size=100, # Number of observations per batch\n",
    "                      validation_data=(X_test, y_test)) # Data for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T19:04:15.039954Z",
     "start_time": "2020-01-03T19:04:15.021279Z"
    }
   },
   "outputs": [],
   "source": [
    "model.predict(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applied:Create a Regression NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T19:05:21.107987Z",
     "start_time": "2020-01-03T19:05:17.539706Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "import keras\n",
    "from keras.layers import Dense\n",
    "from keras.models import Sequential\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T19:05:24.053753Z",
     "start_time": "2020-01-03T19:05:21.110205Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/learn-co-students/nyc-mhtn-ds-042219-lectures/master/Module_4/kc_feat_engineering_project_revamp/kc_housing_data_for_feat_engineering_lab.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T19:34:08.788177Z",
     "start_time": "2020-01-03T19:34:08.766661Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>...</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "      <th>yr_old</th>\n",
       "      <th>year_sold</th>\n",
       "      <th>since_sold</th>\n",
       "      <th>price_log</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7129300520</th>\n",
       "      <td>2014-10-13</td>\n",
       "      <td>221900.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "      <td>62</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>12.309982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6414100192</th>\n",
       "      <td>2014-12-09</td>\n",
       "      <td>538000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "      <td>66</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>13.195614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5631500400</th>\n",
       "      <td>2015-02-25</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "      <td>84</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>12.100712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2487200875</th>\n",
       "      <td>2014-12-09</td>\n",
       "      <td>604000.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "      <td>52</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>13.311329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1954400510</th>\n",
       "      <td>2015-02-18</td>\n",
       "      <td>510000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "      <td>30</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>13.142166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date     price  bedrooms  bathrooms  sqft_living  sqft_lot  \\\n",
       "id                                                                             \n",
       "7129300520  2014-10-13  221900.0         3       1.00         1180      5650   \n",
       "6414100192  2014-12-09  538000.0         3       2.25         2570      7242   \n",
       "5631500400  2015-02-25  180000.0         2       1.00          770     10000   \n",
       "2487200875  2014-12-09  604000.0         4       3.00         1960      5000   \n",
       "1954400510  2015-02-18  510000.0         3       2.00         1680      8080   \n",
       "\n",
       "            floors  waterfront  view  condition  ...  yr_renovated  zipcode  \\\n",
       "id                                               ...                          \n",
       "7129300520     1.0           0     0          3  ...             0    98178   \n",
       "6414100192     2.0           0     0          3  ...          1991    98125   \n",
       "5631500400     1.0           0     0          3  ...             0    98028   \n",
       "2487200875     1.0           0     0          5  ...             0    98136   \n",
       "1954400510     1.0           0     0          3  ...             0    98074   \n",
       "\n",
       "                lat     long  sqft_living15  sqft_lot15  yr_old  year_sold  \\\n",
       "id                                                                           \n",
       "7129300520  47.5112 -122.257           1340        5650      62       2014   \n",
       "6414100192  47.7210 -122.319           1690        7639      66       2014   \n",
       "5631500400  47.7379 -122.233           2720        8062      84       2015   \n",
       "2487200875  47.5208 -122.393           1360        5000      52       2014   \n",
       "1954400510  47.6168 -122.045           1800        7503      30       2015   \n",
       "\n",
       "            since_sold  price_log  \n",
       "id                                 \n",
       "7129300520           3  12.309982  \n",
       "6414100192           3  13.195614  \n",
       "5631500400           2  12.100712  \n",
       "2487200875           3  13.311329  \n",
       "1954400510           2  13.142166  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T19:05:24.090827Z",
     "start_time": "2020-01-03T19:05:24.087404Z"
    }
   },
   "outputs": [],
   "source": [
    "features = ['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot',\n",
    "       'floors', 'waterfront', 'view', 'condition', 'grade', 'sqft_above',\n",
    "       'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode', 'lat', 'long',\n",
    "       'sqft_living15', 'sqft_lot15', 'yr_old', 'since_sold',\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T19:36:14.801550Z",
     "start_time": "2020-01-03T19:36:14.790596Z"
    }
   },
   "outputs": [],
   "source": [
    "y = df['price']\n",
    "X = df[features]\n",
    "df_test = df.sample(frac=.3, replace=True, random_state=1)\n",
    "x_testing = df_test[features]\n",
    "y_testing = df_test['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T19:36:17.702311Z",
     "start_time": "2020-01-03T19:36:17.659042Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "      <th>yr_old</th>\n",
       "      <th>since_sold</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1762600320</th>\n",
       "      <td>5</td>\n",
       "      <td>4.00</td>\n",
       "      <td>3760</td>\n",
       "      <td>28040</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>3760</td>\n",
       "      <td>0</td>\n",
       "      <td>1983</td>\n",
       "      <td>0</td>\n",
       "      <td>98033</td>\n",
       "      <td>47.6489</td>\n",
       "      <td>-122.183</td>\n",
       "      <td>3430</td>\n",
       "      <td>35096</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6610000320</th>\n",
       "      <td>3</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2040</td>\n",
       "      <td>4125</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1540</td>\n",
       "      <td>500</td>\n",
       "      <td>1917</td>\n",
       "      <td>0</td>\n",
       "      <td>98107</td>\n",
       "      <td>47.6608</td>\n",
       "      <td>-122.359</td>\n",
       "      <td>1620</td>\n",
       "      <td>4400</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3475000080</th>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1780</td>\n",
       "      <td>9732</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1780</td>\n",
       "      <td>0</td>\n",
       "      <td>1967</td>\n",
       "      <td>0</td>\n",
       "      <td>98040</td>\n",
       "      <td>47.5796</td>\n",
       "      <td>-122.229</td>\n",
       "      <td>1900</td>\n",
       "      <td>10200</td>\n",
       "      <td>50</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2513500010</th>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>990</td>\n",
       "      <td>4000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>990</td>\n",
       "      <td>0</td>\n",
       "      <td>1911</td>\n",
       "      <td>0</td>\n",
       "      <td>98103</td>\n",
       "      <td>47.6589</td>\n",
       "      <td>-122.341</td>\n",
       "      <td>1560</td>\n",
       "      <td>4000</td>\n",
       "      <td>106</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7199360320</th>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1110</td>\n",
       "      <td>7208</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1110</td>\n",
       "      <td>0</td>\n",
       "      <td>1980</td>\n",
       "      <td>0</td>\n",
       "      <td>98052</td>\n",
       "      <td>47.6979</td>\n",
       "      <td>-122.124</td>\n",
       "      <td>1440</td>\n",
       "      <td>7210</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3332000530</th>\n",
       "      <td>5</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2590</td>\n",
       "      <td>6180</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1330</td>\n",
       "      <td>1260</td>\n",
       "      <td>1960</td>\n",
       "      <td>0</td>\n",
       "      <td>98118</td>\n",
       "      <td>47.5510</td>\n",
       "      <td>-122.272</td>\n",
       "      <td>1560</td>\n",
       "      <td>6180</td>\n",
       "      <td>57</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567000401</th>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2100</td>\n",
       "      <td>1397</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1580</td>\n",
       "      <td>520</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>98144</td>\n",
       "      <td>47.5928</td>\n",
       "      <td>-122.295</td>\n",
       "      <td>1490</td>\n",
       "      <td>1201</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2254502071</th>\n",
       "      <td>2</td>\n",
       "      <td>2.50</td>\n",
       "      <td>750</td>\n",
       "      <td>1430</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>750</td>\n",
       "      <td>0</td>\n",
       "      <td>2006</td>\n",
       "      <td>0</td>\n",
       "      <td>98122</td>\n",
       "      <td>47.6093</td>\n",
       "      <td>-122.310</td>\n",
       "      <td>1320</td>\n",
       "      <td>2790</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6071600370</th>\n",
       "      <td>4</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2030</td>\n",
       "      <td>8517</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1380</td>\n",
       "      <td>650</td>\n",
       "      <td>1961</td>\n",
       "      <td>0</td>\n",
       "      <td>98006</td>\n",
       "      <td>47.5495</td>\n",
       "      <td>-122.174</td>\n",
       "      <td>2230</td>\n",
       "      <td>8824</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6666830390</th>\n",
       "      <td>5</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2590</td>\n",
       "      <td>7084</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2590</td>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>98052</td>\n",
       "      <td>47.7053</td>\n",
       "      <td>-122.113</td>\n",
       "      <td>3010</td>\n",
       "      <td>4823</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7802900224</th>\n",
       "      <td>5</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2860</td>\n",
       "      <td>68519</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>2860</td>\n",
       "      <td>0</td>\n",
       "      <td>1958</td>\n",
       "      <td>0</td>\n",
       "      <td>98065</td>\n",
       "      <td>47.5265</td>\n",
       "      <td>-121.835</td>\n",
       "      <td>1670</td>\n",
       "      <td>35910</td>\n",
       "      <td>59</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1862400353</th>\n",
       "      <td>4</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2690</td>\n",
       "      <td>5400</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2210</td>\n",
       "      <td>480</td>\n",
       "      <td>1940</td>\n",
       "      <td>2009</td>\n",
       "      <td>98117</td>\n",
       "      <td>47.6963</td>\n",
       "      <td>-122.367</td>\n",
       "      <td>1620</td>\n",
       "      <td>5400</td>\n",
       "      <td>77</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1310700390</th>\n",
       "      <td>5</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2630</td>\n",
       "      <td>8625</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2630</td>\n",
       "      <td>0</td>\n",
       "      <td>1966</td>\n",
       "      <td>0</td>\n",
       "      <td>98032</td>\n",
       "      <td>47.3619</td>\n",
       "      <td>-122.287</td>\n",
       "      <td>1880</td>\n",
       "      <td>8670</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523059201</th>\n",
       "      <td>3</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2280</td>\n",
       "      <td>77972</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1460</td>\n",
       "      <td>820</td>\n",
       "      <td>1977</td>\n",
       "      <td>0</td>\n",
       "      <td>98059</td>\n",
       "      <td>47.4804</td>\n",
       "      <td>-122.151</td>\n",
       "      <td>2460</td>\n",
       "      <td>14430</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1336300610</th>\n",
       "      <td>4</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2040</td>\n",
       "      <td>5000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>2040</td>\n",
       "      <td>0</td>\n",
       "      <td>1921</td>\n",
       "      <td>0</td>\n",
       "      <td>98102</td>\n",
       "      <td>47.6279</td>\n",
       "      <td>-122.315</td>\n",
       "      <td>3220</td>\n",
       "      <td>5600</td>\n",
       "      <td>96</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3176100110</th>\n",
       "      <td>3</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1630</td>\n",
       "      <td>7475</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1160</td>\n",
       "      <td>470</td>\n",
       "      <td>1940</td>\n",
       "      <td>0</td>\n",
       "      <td>98115</td>\n",
       "      <td>47.6725</td>\n",
       "      <td>-122.272</td>\n",
       "      <td>2320</td>\n",
       "      <td>7475</td>\n",
       "      <td>77</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7950700110</th>\n",
       "      <td>3</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1100</td>\n",
       "      <td>10125</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1100</td>\n",
       "      <td>0</td>\n",
       "      <td>1969</td>\n",
       "      <td>0</td>\n",
       "      <td>98092</td>\n",
       "      <td>47.3232</td>\n",
       "      <td>-122.103</td>\n",
       "      <td>1520</td>\n",
       "      <td>10125</td>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9358001590</th>\n",
       "      <td>5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1880</td>\n",
       "      <td>3774</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>1360</td>\n",
       "      <td>520</td>\n",
       "      <td>1917</td>\n",
       "      <td>0</td>\n",
       "      <td>98126</td>\n",
       "      <td>47.5660</td>\n",
       "      <td>-122.370</td>\n",
       "      <td>1420</td>\n",
       "      <td>2550</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7853430690</th>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3310</td>\n",
       "      <td>4682</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2380</td>\n",
       "      <td>930</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "      <td>98065</td>\n",
       "      <td>47.5201</td>\n",
       "      <td>-121.885</td>\n",
       "      <td>2660</td>\n",
       "      <td>5166</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5690500095</th>\n",
       "      <td>3</td>\n",
       "      <td>3.25</td>\n",
       "      <td>2960</td>\n",
       "      <td>39370</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>2960</td>\n",
       "      <td>0</td>\n",
       "      <td>1989</td>\n",
       "      <td>0</td>\n",
       "      <td>98011</td>\n",
       "      <td>47.7452</td>\n",
       "      <td>-122.202</td>\n",
       "      <td>2960</td>\n",
       "      <td>56628</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7427800080</th>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1810</td>\n",
       "      <td>5107</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1810</td>\n",
       "      <td>0</td>\n",
       "      <td>1989</td>\n",
       "      <td>0</td>\n",
       "      <td>98033</td>\n",
       "      <td>47.6882</td>\n",
       "      <td>-122.171</td>\n",
       "      <td>1760</td>\n",
       "      <td>5454</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3303850330</th>\n",
       "      <td>4</td>\n",
       "      <td>3.25</td>\n",
       "      <td>5080</td>\n",
       "      <td>27755</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>5080</td>\n",
       "      <td>0</td>\n",
       "      <td>2001</td>\n",
       "      <td>0</td>\n",
       "      <td>98006</td>\n",
       "      <td>47.5423</td>\n",
       "      <td>-122.111</td>\n",
       "      <td>4730</td>\n",
       "      <td>22326</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5469501410</th>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3480</td>\n",
       "      <td>12696</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1980</td>\n",
       "      <td>1500</td>\n",
       "      <td>1977</td>\n",
       "      <td>0</td>\n",
       "      <td>98042</td>\n",
       "      <td>47.3816</td>\n",
       "      <td>-122.153</td>\n",
       "      <td>3480</td>\n",
       "      <td>14175</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3134100023</th>\n",
       "      <td>4</td>\n",
       "      <td>4.25</td>\n",
       "      <td>4980</td>\n",
       "      <td>13000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>3080</td>\n",
       "      <td>1900</td>\n",
       "      <td>1982</td>\n",
       "      <td>0</td>\n",
       "      <td>98052</td>\n",
       "      <td>47.6406</td>\n",
       "      <td>-122.101</td>\n",
       "      <td>2840</td>\n",
       "      <td>11308</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2623089141</th>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2250</td>\n",
       "      <td>50155</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2250</td>\n",
       "      <td>0</td>\n",
       "      <td>1998</td>\n",
       "      <td>0</td>\n",
       "      <td>98045</td>\n",
       "      <td>47.4490</td>\n",
       "      <td>-121.756</td>\n",
       "      <td>2040</td>\n",
       "      <td>57857</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4137010260</th>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2200</td>\n",
       "      <td>8375</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2200</td>\n",
       "      <td>0</td>\n",
       "      <td>1988</td>\n",
       "      <td>0</td>\n",
       "      <td>98092</td>\n",
       "      <td>47.2626</td>\n",
       "      <td>-122.218</td>\n",
       "      <td>2200</td>\n",
       "      <td>10002</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1941400080</th>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1610</td>\n",
       "      <td>11920</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1110</td>\n",
       "      <td>500</td>\n",
       "      <td>1968</td>\n",
       "      <td>0</td>\n",
       "      <td>98032</td>\n",
       "      <td>47.3683</td>\n",
       "      <td>-122.279</td>\n",
       "      <td>1690</td>\n",
       "      <td>11839</td>\n",
       "      <td>49</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5700004028</th>\n",
       "      <td>4</td>\n",
       "      <td>4.25</td>\n",
       "      <td>4250</td>\n",
       "      <td>6552</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>2870</td>\n",
       "      <td>1380</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>98144</td>\n",
       "      <td>47.5747</td>\n",
       "      <td>-122.283</td>\n",
       "      <td>3640</td>\n",
       "      <td>8841</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8835900015</th>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1600</td>\n",
       "      <td>7161</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1600</td>\n",
       "      <td>0</td>\n",
       "      <td>1953</td>\n",
       "      <td>0</td>\n",
       "      <td>98118</td>\n",
       "      <td>47.5507</td>\n",
       "      <td>-122.261</td>\n",
       "      <td>1760</td>\n",
       "      <td>8280</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821069025</th>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3290</td>\n",
       "      <td>90796</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>3290</td>\n",
       "      <td>0</td>\n",
       "      <td>1992</td>\n",
       "      <td>0</td>\n",
       "      <td>98042</td>\n",
       "      <td>47.3154</td>\n",
       "      <td>-122.079</td>\n",
       "      <td>2700</td>\n",
       "      <td>55023</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193000190</th>\n",
       "      <td>4</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2670</td>\n",
       "      <td>6250</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2020</td>\n",
       "      <td>650</td>\n",
       "      <td>1941</td>\n",
       "      <td>0</td>\n",
       "      <td>98199</td>\n",
       "      <td>47.6499</td>\n",
       "      <td>-122.391</td>\n",
       "      <td>1820</td>\n",
       "      <td>6250</td>\n",
       "      <td>76</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>625069064</th>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>47480</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2570</td>\n",
       "      <td>0</td>\n",
       "      <td>1979</td>\n",
       "      <td>0</td>\n",
       "      <td>98053</td>\n",
       "      <td>47.6854</td>\n",
       "      <td>-122.079</td>\n",
       "      <td>2570</td>\n",
       "      <td>106722</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2492200055</th>\n",
       "      <td>3</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1880</td>\n",
       "      <td>5752</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>940</td>\n",
       "      <td>940</td>\n",
       "      <td>1945</td>\n",
       "      <td>0</td>\n",
       "      <td>98126</td>\n",
       "      <td>47.5354</td>\n",
       "      <td>-122.378</td>\n",
       "      <td>1110</td>\n",
       "      <td>5201</td>\n",
       "      <td>72</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486000597</th>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2930</td>\n",
       "      <td>7005</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2670</td>\n",
       "      <td>260</td>\n",
       "      <td>1999</td>\n",
       "      <td>0</td>\n",
       "      <td>98117</td>\n",
       "      <td>47.6763</td>\n",
       "      <td>-122.404</td>\n",
       "      <td>2450</td>\n",
       "      <td>6460</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7767400060</th>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2300</td>\n",
       "      <td>7314</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1420</td>\n",
       "      <td>880</td>\n",
       "      <td>1979</td>\n",
       "      <td>0</td>\n",
       "      <td>98133</td>\n",
       "      <td>47.7671</td>\n",
       "      <td>-122.330</td>\n",
       "      <td>2010</td>\n",
       "      <td>7314</td>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008000130</th>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3300</td>\n",
       "      <td>11525</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1650</td>\n",
       "      <td>1650</td>\n",
       "      <td>1961</td>\n",
       "      <td>0</td>\n",
       "      <td>98198</td>\n",
       "      <td>47.4113</td>\n",
       "      <td>-122.315</td>\n",
       "      <td>1950</td>\n",
       "      <td>9680</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9510310280</th>\n",
       "      <td>4</td>\n",
       "      <td>3.50</td>\n",
       "      <td>3650</td>\n",
       "      <td>38546</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2550</td>\n",
       "      <td>1100</td>\n",
       "      <td>1996</td>\n",
       "      <td>0</td>\n",
       "      <td>98045</td>\n",
       "      <td>47.4776</td>\n",
       "      <td>-121.730</td>\n",
       "      <td>2860</td>\n",
       "      <td>34284</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2125059124</th>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>3020</td>\n",
       "      <td>43560</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>2720</td>\n",
       "      <td>300</td>\n",
       "      <td>1969</td>\n",
       "      <td>0</td>\n",
       "      <td>98005</td>\n",
       "      <td>47.6456</td>\n",
       "      <td>-122.173</td>\n",
       "      <td>3910</td>\n",
       "      <td>43560</td>\n",
       "      <td>48</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2493200040</th>\n",
       "      <td>2</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2910</td>\n",
       "      <td>6110</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>2910</td>\n",
       "      <td>0</td>\n",
       "      <td>1985</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5279</td>\n",
       "      <td>-122.387</td>\n",
       "      <td>2090</td>\n",
       "      <td>5763</td>\n",
       "      <td>32</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6372000101</th>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1200</td>\n",
       "      <td>2016</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>600</td>\n",
       "      <td>600</td>\n",
       "      <td>1931</td>\n",
       "      <td>0</td>\n",
       "      <td>98116</td>\n",
       "      <td>47.5811</td>\n",
       "      <td>-122.404</td>\n",
       "      <td>1730</td>\n",
       "      <td>4520</td>\n",
       "      <td>86</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9542830690</th>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2020</td>\n",
       "      <td>4183</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2020</td>\n",
       "      <td>0</td>\n",
       "      <td>2012</td>\n",
       "      <td>0</td>\n",
       "      <td>98038</td>\n",
       "      <td>47.3658</td>\n",
       "      <td>-122.017</td>\n",
       "      <td>2030</td>\n",
       "      <td>4140</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4134300175</th>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>4120</td>\n",
       "      <td>14866</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2070</td>\n",
       "      <td>2050</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98006</td>\n",
       "      <td>47.5571</td>\n",
       "      <td>-122.193</td>\n",
       "      <td>3620</td>\n",
       "      <td>19729</td>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1624049087</th>\n",
       "      <td>2</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2470</td>\n",
       "      <td>8840</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>1780</td>\n",
       "      <td>690</td>\n",
       "      <td>2001</td>\n",
       "      <td>0</td>\n",
       "      <td>98108</td>\n",
       "      <td>47.5693</td>\n",
       "      <td>-122.301</td>\n",
       "      <td>1940</td>\n",
       "      <td>8840</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5361700020</th>\n",
       "      <td>3</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1450</td>\n",
       "      <td>7316</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1450</td>\n",
       "      <td>0</td>\n",
       "      <td>1961</td>\n",
       "      <td>0</td>\n",
       "      <td>98133</td>\n",
       "      <td>47.7725</td>\n",
       "      <td>-122.349</td>\n",
       "      <td>1440</td>\n",
       "      <td>7316</td>\n",
       "      <td>56</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3904901450</th>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1850</td>\n",
       "      <td>4050</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1850</td>\n",
       "      <td>0</td>\n",
       "      <td>1985</td>\n",
       "      <td>0</td>\n",
       "      <td>98029</td>\n",
       "      <td>47.5669</td>\n",
       "      <td>-122.017</td>\n",
       "      <td>1650</td>\n",
       "      <td>4468</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6751500185</th>\n",
       "      <td>5</td>\n",
       "      <td>3.00</td>\n",
       "      <td>2750</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1730</td>\n",
       "      <td>1020</td>\n",
       "      <td>1957</td>\n",
       "      <td>0</td>\n",
       "      <td>98008</td>\n",
       "      <td>47.5878</td>\n",
       "      <td>-122.130</td>\n",
       "      <td>2520</td>\n",
       "      <td>10000</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2616800050</th>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2490</td>\n",
       "      <td>34947</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2150</td>\n",
       "      <td>340</td>\n",
       "      <td>1985</td>\n",
       "      <td>0</td>\n",
       "      <td>98027</td>\n",
       "      <td>47.4823</td>\n",
       "      <td>-122.031</td>\n",
       "      <td>2490</td>\n",
       "      <td>39639</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3832710450</th>\n",
       "      <td>4</td>\n",
       "      <td>2.75</td>\n",
       "      <td>1500</td>\n",
       "      <td>7036</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1060</td>\n",
       "      <td>440</td>\n",
       "      <td>1979</td>\n",
       "      <td>0</td>\n",
       "      <td>98032</td>\n",
       "      <td>47.3665</td>\n",
       "      <td>-122.276</td>\n",
       "      <td>1620</td>\n",
       "      <td>7200</td>\n",
       "      <td>38</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2190601055</th>\n",
       "      <td>4</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2700</td>\n",
       "      <td>27072</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1380</td>\n",
       "      <td>1320</td>\n",
       "      <td>1958</td>\n",
       "      <td>0</td>\n",
       "      <td>98003</td>\n",
       "      <td>47.2877</td>\n",
       "      <td>-122.293</td>\n",
       "      <td>2460</td>\n",
       "      <td>34850</td>\n",
       "      <td>59</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3275870080</th>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2910</td>\n",
       "      <td>15016</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>2910</td>\n",
       "      <td>0</td>\n",
       "      <td>1990</td>\n",
       "      <td>0</td>\n",
       "      <td>98052</td>\n",
       "      <td>47.6900</td>\n",
       "      <td>-122.097</td>\n",
       "      <td>2870</td>\n",
       "      <td>13992</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4356200210</th>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>890</td>\n",
       "      <td>4810</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>890</td>\n",
       "      <td>0</td>\n",
       "      <td>1910</td>\n",
       "      <td>0</td>\n",
       "      <td>98118</td>\n",
       "      <td>47.5153</td>\n",
       "      <td>-122.266</td>\n",
       "      <td>1230</td>\n",
       "      <td>6057</td>\n",
       "      <td>107</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1771100030</th>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1120</td>\n",
       "      <td>9075</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1120</td>\n",
       "      <td>0</td>\n",
       "      <td>1977</td>\n",
       "      <td>0</td>\n",
       "      <td>98077</td>\n",
       "      <td>47.7551</td>\n",
       "      <td>-122.072</td>\n",
       "      <td>1120</td>\n",
       "      <td>9705</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4057300030</th>\n",
       "      <td>3</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1140</td>\n",
       "      <td>3292</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1140</td>\n",
       "      <td>0</td>\n",
       "      <td>1988</td>\n",
       "      <td>0</td>\n",
       "      <td>98029</td>\n",
       "      <td>47.5701</td>\n",
       "      <td>-122.017</td>\n",
       "      <td>1150</td>\n",
       "      <td>3592</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>824079032</th>\n",
       "      <td>4</td>\n",
       "      <td>1.75</td>\n",
       "      <td>2085</td>\n",
       "      <td>174240</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>1610</td>\n",
       "      <td>475</td>\n",
       "      <td>1964</td>\n",
       "      <td>0</td>\n",
       "      <td>98024</td>\n",
       "      <td>47.5753</td>\n",
       "      <td>-121.950</td>\n",
       "      <td>2690</td>\n",
       "      <td>174240</td>\n",
       "      <td>53</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5169700132</th>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2630</td>\n",
       "      <td>6283</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2630</td>\n",
       "      <td>0</td>\n",
       "      <td>2006</td>\n",
       "      <td>0</td>\n",
       "      <td>98059</td>\n",
       "      <td>47.5079</td>\n",
       "      <td>-122.158</td>\n",
       "      <td>2630</td>\n",
       "      <td>7210</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452002005</th>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>980</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>980</td>\n",
       "      <td>0</td>\n",
       "      <td>1904</td>\n",
       "      <td>0</td>\n",
       "      <td>98107</td>\n",
       "      <td>47.6744</td>\n",
       "      <td>-122.369</td>\n",
       "      <td>1270</td>\n",
       "      <td>4500</td>\n",
       "      <td>113</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1951100110</th>\n",
       "      <td>3</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1630</td>\n",
       "      <td>9450</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1080</td>\n",
       "      <td>550</td>\n",
       "      <td>1977</td>\n",
       "      <td>0</td>\n",
       "      <td>98032</td>\n",
       "      <td>47.3729</td>\n",
       "      <td>-122.295</td>\n",
       "      <td>1280</td>\n",
       "      <td>9100</td>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8658303585</th>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>900</td>\n",
       "      <td>7500</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>900</td>\n",
       "      <td>0</td>\n",
       "      <td>1961</td>\n",
       "      <td>0</td>\n",
       "      <td>98014</td>\n",
       "      <td>47.6481</td>\n",
       "      <td>-121.916</td>\n",
       "      <td>1190</td>\n",
       "      <td>10000</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1748800120</th>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>3250</td>\n",
       "      <td>4650</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>3250</td>\n",
       "      <td>0</td>\n",
       "      <td>2007</td>\n",
       "      <td>0</td>\n",
       "      <td>98031</td>\n",
       "      <td>47.4004</td>\n",
       "      <td>-122.203</td>\n",
       "      <td>2960</td>\n",
       "      <td>4650</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5490210320</th>\n",
       "      <td>5</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2500</td>\n",
       "      <td>7200</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1490</td>\n",
       "      <td>1010</td>\n",
       "      <td>1977</td>\n",
       "      <td>0</td>\n",
       "      <td>98052</td>\n",
       "      <td>47.6964</td>\n",
       "      <td>-122.120</td>\n",
       "      <td>1960</td>\n",
       "      <td>8325</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6480 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            bedrooms  bathrooms  sqft_living  sqft_lot  floors  waterfront  \\\n",
       "id                                                                           \n",
       "1762600320         5       4.00         3760     28040     2.0           0   \n",
       "6610000320         3       1.75         2040      4125     1.5           0   \n",
       "3475000080         3       2.00         1780      9732     1.0           0   \n",
       "2513500010         2       1.00          990      4000     1.0           0   \n",
       "7199360320         3       1.00         1110      7208     1.0           0   \n",
       "3332000530         5       3.25         2590      6180     1.0           0   \n",
       "567000401          4       2.50         2100      1397     3.0           0   \n",
       "2254502071         2       2.50          750      1430     2.0           0   \n",
       "6071600370         4       2.25         2030      8517     1.0           0   \n",
       "6666830390         5       2.50         2590      7084     2.0           0   \n",
       "7802900224         5       2.50         2860     68519     2.0           0   \n",
       "1862400353         4       2.75         2690      5400     2.0           0   \n",
       "1310700390         5       2.25         2630      8625     2.0           0   \n",
       "1523059201         3       1.75         2280     77972     1.0           0   \n",
       "1336300610         4       1.75         2040      5000     2.0           0   \n",
       "3176100110         3       1.50         1630      7475     1.0           0   \n",
       "7950700110         3       1.75         1100     10125     1.0           0   \n",
       "9358001590         5       1.00         1880      3774     1.5           0   \n",
       "7853430690         3       2.50         3310      4682     2.0           0   \n",
       "5690500095         3       3.25         2960     39370     2.0           0   \n",
       "7427800080         3       2.25         1810      5107     2.0           0   \n",
       "3303850330         4       3.25         5080     27755     2.0           0   \n",
       "5469501410         4       2.50         3480     12696     1.0           0   \n",
       "3134100023         4       4.25         4980     13000     2.0           0   \n",
       "2623089141         4       2.50         2250     50155     2.0           0   \n",
       "4137010260         3       2.25         2200      8375     2.0           0   \n",
       "1941400080         3       2.25         1610     11920     1.0           0   \n",
       "5700004028         4       4.25         4250      6552     2.0           0   \n",
       "8835900015         3       1.00         1600      7161     1.0           0   \n",
       "821069025          3       2.50         3290     90796     2.0           0   \n",
       "...              ...        ...          ...       ...     ...         ...   \n",
       "1193000190         4       1.75         2670      6250     2.0           0   \n",
       "625069064          3       2.25         2570     47480     1.0           0   \n",
       "2492200055         3       1.75         1880      5752     1.0           0   \n",
       "486000597          3       2.25         2930      7005     3.0           0   \n",
       "7767400060         4       2.50         2300      7314     1.0           0   \n",
       "2008000130         3       2.50         3300     11525     1.0           0   \n",
       "9510310280         4       3.50         3650     38546     2.0           0   \n",
       "2125059124         3       2.25         3020     43560     2.0           0   \n",
       "2493200040         2       2.25         2910      6110     2.0           0   \n",
       "6372000101         3       2.00         1200      2016     1.0           0   \n",
       "9542830690         3       2.50         2020      4183     2.0           0   \n",
       "4134300175         4       2.50         4120     14866     1.0           1   \n",
       "1624049087         2       2.50         2470      8840     2.0           0   \n",
       "5361700020         3       1.50         1450      7316     1.0           0   \n",
       "3904901450         3       2.25         1850      4050     2.0           0   \n",
       "6751500185         5       3.00         2750     10000     1.0           0   \n",
       "2616800050         4       2.50         2490     34947     2.0           0   \n",
       "3832710450         4       2.75         1500      7036     1.0           0   \n",
       "2190601055         4       1.75         2700     27072     1.0           0   \n",
       "3275870080         4       2.50         2910     15016     2.0           0   \n",
       "4356200210         3       1.00          890      4810     1.0           0   \n",
       "1771100030         3       1.00         1120      9075     1.0           0   \n",
       "4057300030         3       1.50         1140      3292     2.0           0   \n",
       "824079032          4       1.75         2085    174240     1.0           0   \n",
       "5169700132         4       2.50         2630      6283     2.0           0   \n",
       "452002005          2       1.00          980      5000     1.0           0   \n",
       "1951100110         3       1.75         1630      9450     1.0           0   \n",
       "8658303585         2       1.00          900      7500     1.0           0   \n",
       "1748800120         4       2.50         3250      4650     2.0           0   \n",
       "5490210320         5       2.50         2500      7200     1.0           0   \n",
       "\n",
       "            view  condition  grade  sqft_above  sqft_basement  yr_built  \\\n",
       "id                                                                        \n",
       "1762600320     0          3     10        3760              0      1983   \n",
       "6610000320     0          4      8        1540            500      1917   \n",
       "3475000080     0          3      8        1780              0      1967   \n",
       "2513500010     0          4      7         990              0      1911   \n",
       "7199360320     0          3      7        1110              0      1980   \n",
       "3332000530     0          3      7        1330           1260      1960   \n",
       "567000401      0          3      8        1580            520      2008   \n",
       "2254502071     0          3      8         750              0      2006   \n",
       "6071600370     0          4      8        1380            650      1961   \n",
       "6666830390     0          3      8        2590              0      2014   \n",
       "7802900224     0          5      8        2860              0      1958   \n",
       "1862400353     0          3      7        2210            480      1940   \n",
       "1310700390     0          3      8        2630              0      1966   \n",
       "1523059201     0          3      8        1460            820      1977   \n",
       "1336300610     0          4      9        2040              0      1921   \n",
       "3176100110     1          3      7        1160            470      1940   \n",
       "7950700110     0          4      7        1100              0      1969   \n",
       "9358001590     0          3      6        1360            520      1917   \n",
       "7853430690     0          3      9        2380            930      2015   \n",
       "5690500095     0          3     10        2960              0      1989   \n",
       "7427800080     0          3      8        1810              0      1989   \n",
       "3303850330     0          3     11        5080              0      2001   \n",
       "5469501410     0          4      9        1980           1500      1977   \n",
       "3134100023     3          3      9        3080           1900      1982   \n",
       "2623089141     0          3      8        2250              0      1998   \n",
       "4137010260     0          3      8        2200              0      1988   \n",
       "1941400080     0          4      7        1110            500      1968   \n",
       "5700004028     3          4     10        2870           1380      2008   \n",
       "8835900015     0          3      8        1600              0      1953   \n",
       "821069025      0          4     10        3290              0      1992   \n",
       "...          ...        ...    ...         ...            ...       ...   \n",
       "1193000190     0          4      8        2020            650      1941   \n",
       "625069064      0          3      9        2570              0      1979   \n",
       "2492200055     0          4      7         940            940      1945   \n",
       "486000597      2          3      9        2670            260      1999   \n",
       "7767400060     0          4      8        1420            880      1979   \n",
       "2008000130     0          5      8        1650           1650      1961   \n",
       "9510310280     0          3      9        2550           1100      1996   \n",
       "2125059124     0          3     10        2720            300      1969   \n",
       "2493200040     2          4      9        2910              0      1985   \n",
       "6372000101     1          4      7         600            600      1931   \n",
       "9542830690     0          3      7        2020              0      2012   \n",
       "4134300175     4          3      8        2070           2050      1965   \n",
       "1624049087     0          4      8        1780            690      2001   \n",
       "5361700020     0          3      7        1450              0      1961   \n",
       "3904901450     0          4      7        1850              0      1985   \n",
       "6751500185     0          4      7        1730           1020      1957   \n",
       "2616800050     0          3      9        2150            340      1985   \n",
       "3832710450     0          3      7        1060            440      1979   \n",
       "2190601055     0          3      7        1380           1320      1958   \n",
       "3275870080     0          3     10        2910              0      1990   \n",
       "4356200210     0          3      6         890              0      1910   \n",
       "1771100030     0          3      7        1120              0      1977   \n",
       "4057300030     0          3      7        1140              0      1988   \n",
       "824079032      0          3      7        1610            475      1964   \n",
       "5169700132     0          3      9        2630              0      2006   \n",
       "452002005      0          3      6         980              0      1904   \n",
       "1951100110     0          4      7        1080            550      1977   \n",
       "8658303585     0          4      6         900              0      1961   \n",
       "1748800120     0          3      8        3250              0      2007   \n",
       "5490210320     0          4      7        1490           1010      1977   \n",
       "\n",
       "            yr_renovated  zipcode      lat     long  sqft_living15  \\\n",
       "id                                                                   \n",
       "1762600320             0    98033  47.6489 -122.183           3430   \n",
       "6610000320             0    98107  47.6608 -122.359           1620   \n",
       "3475000080             0    98040  47.5796 -122.229           1900   \n",
       "2513500010             0    98103  47.6589 -122.341           1560   \n",
       "7199360320             0    98052  47.6979 -122.124           1440   \n",
       "3332000530             0    98118  47.5510 -122.272           1560   \n",
       "567000401              0    98144  47.5928 -122.295           1490   \n",
       "2254502071             0    98122  47.6093 -122.310           1320   \n",
       "6071600370             0    98006  47.5495 -122.174           2230   \n",
       "6666830390             0    98052  47.7053 -122.113           3010   \n",
       "7802900224             0    98065  47.5265 -121.835           1670   \n",
       "1862400353          2009    98117  47.6963 -122.367           1620   \n",
       "1310700390             0    98032  47.3619 -122.287           1880   \n",
       "1523059201             0    98059  47.4804 -122.151           2460   \n",
       "1336300610             0    98102  47.6279 -122.315           3220   \n",
       "3176100110             0    98115  47.6725 -122.272           2320   \n",
       "7950700110             0    98092  47.3232 -122.103           1520   \n",
       "9358001590             0    98126  47.5660 -122.370           1420   \n",
       "7853430690             0    98065  47.5201 -121.885           2660   \n",
       "5690500095             0    98011  47.7452 -122.202           2960   \n",
       "7427800080             0    98033  47.6882 -122.171           1760   \n",
       "3303850330             0    98006  47.5423 -122.111           4730   \n",
       "5469501410             0    98042  47.3816 -122.153           3480   \n",
       "3134100023             0    98052  47.6406 -122.101           2840   \n",
       "2623089141             0    98045  47.4490 -121.756           2040   \n",
       "4137010260             0    98092  47.2626 -122.218           2200   \n",
       "1941400080             0    98032  47.3683 -122.279           1690   \n",
       "5700004028             0    98144  47.5747 -122.283           3640   \n",
       "8835900015             0    98118  47.5507 -122.261           1760   \n",
       "821069025              0    98042  47.3154 -122.079           2700   \n",
       "...                  ...      ...      ...      ...            ...   \n",
       "1193000190             0    98199  47.6499 -122.391           1820   \n",
       "625069064              0    98053  47.6854 -122.079           2570   \n",
       "2492200055             0    98126  47.5354 -122.378           1110   \n",
       "486000597              0    98117  47.6763 -122.404           2450   \n",
       "7767400060             0    98133  47.7671 -122.330           2010   \n",
       "2008000130             0    98198  47.4113 -122.315           1950   \n",
       "9510310280             0    98045  47.4776 -121.730           2860   \n",
       "2125059124             0    98005  47.6456 -122.173           3910   \n",
       "2493200040             0    98136  47.5279 -122.387           2090   \n",
       "6372000101             0    98116  47.5811 -122.404           1730   \n",
       "9542830690             0    98038  47.3658 -122.017           2030   \n",
       "4134300175             0    98006  47.5571 -122.193           3620   \n",
       "1624049087             0    98108  47.5693 -122.301           1940   \n",
       "5361700020             0    98133  47.7725 -122.349           1440   \n",
       "3904901450             0    98029  47.5669 -122.017           1650   \n",
       "6751500185             0    98008  47.5878 -122.130           2520   \n",
       "2616800050             0    98027  47.4823 -122.031           2490   \n",
       "3832710450             0    98032  47.3665 -122.276           1620   \n",
       "2190601055             0    98003  47.2877 -122.293           2460   \n",
       "3275870080             0    98052  47.6900 -122.097           2870   \n",
       "4356200210             0    98118  47.5153 -122.266           1230   \n",
       "1771100030             0    98077  47.7551 -122.072           1120   \n",
       "4057300030             0    98029  47.5701 -122.017           1150   \n",
       "824079032              0    98024  47.5753 -121.950           2690   \n",
       "5169700132             0    98059  47.5079 -122.158           2630   \n",
       "452002005              0    98107  47.6744 -122.369           1270   \n",
       "1951100110             0    98032  47.3729 -122.295           1280   \n",
       "8658303585             0    98014  47.6481 -121.916           1190   \n",
       "1748800120             0    98031  47.4004 -122.203           2960   \n",
       "5490210320             0    98052  47.6964 -122.120           1960   \n",
       "\n",
       "            sqft_lot15  yr_old  since_sold  \n",
       "id                                          \n",
       "1762600320       35096      34           3  \n",
       "6610000320        4400     100           3  \n",
       "3475000080       10200      50           3  \n",
       "2513500010        4000     106           2  \n",
       "7199360320        7210      37           2  \n",
       "3332000530        6180      57           3  \n",
       "567000401         1201       9           2  \n",
       "2254502071        2790      11           3  \n",
       "6071600370        8824      56           2  \n",
       "6666830390        4823       3           3  \n",
       "7802900224       35910      59           3  \n",
       "1862400353        5400      77           2  \n",
       "1310700390        8670      51           3  \n",
       "1523059201       14430      40           2  \n",
       "1336300610        5600      96           2  \n",
       "3176100110        7475      77           3  \n",
       "7950700110       10125      48           3  \n",
       "9358001590        2550     100           2  \n",
       "7853430690        5166       2           2  \n",
       "5690500095       56628      28           3  \n",
       "7427800080        5454      28           2  \n",
       "3303850330       22326      16           3  \n",
       "5469501410       14175      40           3  \n",
       "3134100023       11308      35           3  \n",
       "2623089141       57857      19           3  \n",
       "4137010260       10002      29           3  \n",
       "1941400080       11839      49           3  \n",
       "5700004028        8841       9           2  \n",
       "8835900015        8280      64           3  \n",
       "821069025        55023      25           2  \n",
       "...                ...     ...         ...  \n",
       "1193000190        6250      76           3  \n",
       "625069064       106722      38           2  \n",
       "2492200055        5201      72           3  \n",
       "486000597         6460      18           3  \n",
       "7767400060        7314      38           3  \n",
       "2008000130        9680      56           3  \n",
       "9510310280       34284      21           3  \n",
       "2125059124       43560      48           3  \n",
       "2493200040        5763      32           2  \n",
       "6372000101        4520      86           3  \n",
       "9542830690        4140       5           3  \n",
       "4134300175       19729      52           2  \n",
       "1624049087        8840      16           3  \n",
       "5361700020        7316      56           2  \n",
       "3904901450        4468      32           3  \n",
       "6751500185       10000      60           2  \n",
       "2616800050       39639      32           3  \n",
       "3832710450        7200      38           3  \n",
       "2190601055       34850      59           3  \n",
       "3275870080       13992      27           3  \n",
       "4356200210        6057     107           2  \n",
       "1771100030        9705      40           2  \n",
       "4057300030        3592      29           3  \n",
       "824079032       174240      53           3  \n",
       "5169700132        7210      11           2  \n",
       "452002005         4500     113           2  \n",
       "1951100110        9100      40           2  \n",
       "8658303585       10000      56           3  \n",
       "1748800120        4650      10           2  \n",
       "5490210320        8325      40           3  \n",
       "\n",
       "[6480 rows x 20 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_testing"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T19:05:24.103248Z",
     "start_time": "2020-01-03T19:05:24.099791Z"
    }
   },
   "source": [
    "len(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Store the number of columns in the predictors data to `n_cols`. This has been done for you.\n",
    "- Start by creating a `Sequential` model called `model`.\n",
    "- Use the `.add()` method on `model` to add a `Dense` layer.\n",
    "- Add 50 units, specify `activation='relu'`, and the `input_shape` parameter to be the tuple `(n_cols,)` which means it has `n_cols` items in each row of data, and any number of rows of data are acceptable as inputs.\n",
    "- Add another `Dense` layer. This should have 32 units and a 'relu' activation.\n",
    "- Finally, add an output layer, which is a `Dense` layer with a single node. Don't use any activation function here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T19:36:28.362003Z",
     "start_time": "2020-01-03T19:36:28.335397Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save the number of columns in predictors: n_cols\n",
    "n_cols = len(features)\n",
    "\n",
    "# Set up the model: model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first layer\n",
    "model.add(Dense(100, activation='relu', input_shape=(n_cols,)))\n",
    "\n",
    "# Add the second layer\n",
    "model.add(Dense(100, activation= 'relu'))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(1))    #1 because are target is one item (price)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Compile the model using `model.compile()`. Your `optimizer` should be `'adam'` and the `loss` should be `'mean_squared_error'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T19:36:29.180768Z",
     "start_time": "2020-01-03T19:36:29.159419Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function: mean_squared_error\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Verify that model contains information from compiling\n",
    "print(\"Loss function: \" + model.loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Fit the `model`. Remember that the first argument is the predictive features (`predictors`), and the data to be predicted (`target`) is the second argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T19:36:41.377816Z",
     "start_time": "2020-01-03T19:36:32.986679Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "21600/21600 [==============================] - 1s 29us/step - loss: 159872105740.5156\n",
      "Epoch 1/15\n",
      " - 0s - loss: 91666431757.2741\n",
      "Epoch 2/15\n",
      " - 0s - loss: 63522502589.2504\n",
      "Epoch 3/15\n",
      " - 0s - loss: 59946694543.7393\n",
      "Epoch 4/15\n",
      " - 1s - loss: 59740172230.3526\n",
      "Epoch 5/15\n",
      " - 0s - loss: 59493980172.1363\n",
      "Epoch 6/15\n",
      " - 0s - loss: 59105863690.6193\n",
      "Epoch 7/15\n",
      " - 0s - loss: 58802121447.3482\n",
      "Epoch 8/15\n",
      " - 1s - loss: 58441509699.8874\n",
      "Epoch 9/15\n",
      " - 1s - loss: 57565022121.5289\n",
      "Epoch 10/15\n",
      " - 1s - loss: 57101260681.6711\n",
      "Epoch 11/15\n",
      " - 1s - loss: 56363029378.0859\n",
      "Epoch 12/15\n",
      " - 0s - loss: 56148222102.1867\n",
      "Epoch 13/15\n",
      " - 0s - loss: 55999244081.6830\n",
      "Epoch 14/15\n",
      " - 0s - loss: 55579391787.6148\n",
      "Epoch 15/15\n",
      " - 0s - loss: 55282399925.2859\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x63c47d940>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X,y) # Data for evaluation\n",
    "\n",
    "model.fit(X,# Features\n",
    "                      y, # Target\n",
    "                      epochs=15, # Number of epochs\n",
    "                      verbose=2, # Some output\n",
    "                      batch_size=32, # Number of observations per batch\n",
    "                      ) # Data for evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T19:40:02.506549Z",
     "start_time": "2020-01-03T19:40:02.425787Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1027727.75 ]\n",
      " [ 580523.06 ]\n",
      " [ 409423.9  ]\n",
      " ...\n",
      " [ 124978.625]\n",
      " [ 879811.   ]\n",
      " [ 596893.4  ]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate predictions: using a sample of the training data\n",
    "predictions = model.predict(x_testing)\n",
    "\n",
    "# print predicted val\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T19:40:39.191355Z",
     "start_time": "2020-01-03T19:40:39.185337Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id\n",
       "1762600320    1025000.0\n",
       "6610000320     710500.0\n",
       "3475000080     710000.0\n",
       "2513500010     747000.0\n",
       "7199360320     411500.0\n",
       "3332000530     599000.0\n",
       "567000401      546000.0\n",
       "2254502071     375000.0\n",
       "6071600370     500000.0\n",
       "6666830390     779380.0\n",
       "7802900224     670000.0\n",
       "1862400353     721000.0\n",
       "1310700390     320000.0\n",
       "1523059201     749700.0\n",
       "1336300610    1272500.0\n",
       "3176100110     650000.0\n",
       "7950700110     224000.0\n",
       "9358001590     340000.0\n",
       "7853430690     572800.0\n",
       "5690500095     735000.0\n",
       "7427800080     626000.0\n",
       "3303850330    1900000.0\n",
       "5469501410     490000.0\n",
       "3134100023    1250000.0\n",
       "2623089141     476500.0\n",
       "4137010260     285167.0\n",
       "1941400080     277000.0\n",
       "5700004028    2450000.0\n",
       "8835900015     475000.0\n",
       "821069025      685000.0\n",
       "                ...    \n",
       "1193000190     750000.0\n",
       "625069064      625000.0\n",
       "2492200055     412000.0\n",
       "486000597     1047500.0\n",
       "7767400060     465000.0\n",
       "2008000130     360500.0\n",
       "9510310280     696000.0\n",
       "2125059124     955000.0\n",
       "2493200040     620000.0\n",
       "6372000101     483500.0\n",
       "9542830690     321000.0\n",
       "4134300175    1851000.0\n",
       "1624049087     635000.0\n",
       "5361700020     430000.0\n",
       "3904901450     445000.0\n",
       "6751500185     795000.0\n",
       "2616800050     520000.0\n",
       "3832710450     262500.0\n",
       "2190601055     314900.0\n",
       "3275870080     765000.0\n",
       "4356200210     153500.0\n",
       "1771100030     335000.0\n",
       "4057300030     310000.0\n",
       "824079032      563500.0\n",
       "5169700132     507950.0\n",
       "452002005      452000.0\n",
       "1951100110     240000.0\n",
       "8658303585     252500.0\n",
       "1748800120     353500.0\n",
       "5490210320     661500.0\n",
       "Name: price, Length: 6480, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T19:40:17.395130Z",
     "start_time": "2020-01-03T19:40:17.390504Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57307351072.64913"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "# Calculate predictions: predictions\n",
    "mean_squared_error(y_testing, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Models\n",
    "\n",
    "\n",
    "- ‘categorical_crossentropy’ loss function Similar to log loss: Lower is be!er\n",
    "- Add metrics = [‘accuracy’] to compile step for easy-to- understand diagnostics\n",
    "- Output layer has separate node for each possible outcome, and uses ‘so\"max’ activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T20:14:12.452787Z",
     "start_time": "2020-01-03T20:14:11.990319Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>youngin</th>\n",
       "      <th>male</th>\n",
       "      <th>Q</th>\n",
       "      <th>S</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass   Age  SibSp  Parch     Fare  youngin  male  Q  \\\n",
       "PassengerId                                                                    \n",
       "1                   0       3  22.0      1      0   7.2500        0     1  0   \n",
       "2                   1       1  38.0      1      0  71.2833        0     0  0   \n",
       "3                   1       3  26.0      0      0   7.9250        0     0  0   \n",
       "4                   1       1  35.0      1      0  53.1000        0     0  0   \n",
       "5                   0       3  35.0      0      0   8.0500        0     1  0   \n",
       "\n",
       "             S  \n",
       "PassengerId     \n",
       "1            1  \n",
       "2            0  \n",
       "3            1  \n",
       "4            1  \n",
       "5            1  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/learn-co-students/nyc-mhtn-ds-042219-lectures/master/Module_4/cleaned_titanic.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T20:14:12.458612Z",
     "start_time": "2020-01-03T20:14:12.454999Z"
    }
   },
   "outputs": [],
   "source": [
    "predictors = df.drop(columns=['Survived'])\n",
    "n_cols = predictors.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Convert `df.Survived` to a categorical variable using the `to_categorical()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T20:14:13.114698Z",
     "start_time": "2020-01-03T20:14:13.111676Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "# Convert the target to categorical: target\n",
    "target = to_categorical(df.Survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T20:14:13.819932Z",
     "start_time": "2020-01-03T20:14:13.805424Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import `train_test_split` from `sklearn.model_selection`\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Split the data up in train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(predictors, target, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T20:14:14.624110Z",
     "start_time": "2020-01-03T20:14:14.620857Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Specify a `Sequential` model called `model`.\n",
    "- Add a `Dense` layer with 32 nodes. Use `'relu'` as the `activation` and `(n_cols,)` as the `input_shape`.\n",
    "- Add the `Dense` output layer. Because there are two outcomes, it should have 2 units, and because it is a classification model, the `activation` should be `'softmax'`.\n",
    "- Compile the model, using `'sgd'` as the `optimizer`, `'categorical_crossentropy'` as the loss function, and `metrics=['accuracy']` to see the accuracy (what fraction of predictions were correct) at the end of each epoch.\n",
    "- Fit the model using the `X_train` and the `y_train`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T19:02:41.713069Z",
     "start_time": "2020-01-03T19:02:41.464885Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "\n",
    "# Convert the target to categorical: target\n",
    "# target = to_categorical(df.Survived)\n",
    "\n",
    "# Set up the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the first layer\n",
    "model.add(Dense(9, activation='relu', input_shape=(n_cols,)))\n",
    "\n",
    "# Add the second layer\n",
    "model.add(Dense(9, activation='relu', input_shape=(n_cols,)))\n",
    "\n",
    "# Add the output layer\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train,y_train) # Data for evaluation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving, reloading and using your Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T17:28:46.962017Z",
     "start_time": "2020-01-03T17:28:46.770292Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model.save('model_file.h5')\n",
    "my_model = load_model('model_file.h5')\n",
    "predictions = my_model.predict(X_test) \n",
    "probability_true = predictions[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Create your predictions using the model's `.predict()` method on `X_test`.\n",
    "- Use NumPy indexing to find the column corresponding to predicted probabilities of survival being True. This is the second column (index `1`) of `predictions`. Store the result in `predicted_prob_true` and print it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T17:31:26.878413Z",
     "start_time": "2020-01-03T17:31:26.870152Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate predictions: predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Calculate predicted probability of survival: predicted_prob_true\n",
    "predicted_prob_true = predictions[:,1]\n",
    "\n",
    "# print predicted_prob_true\n",
    "print(predicted_prob_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify your model structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T17:32:02.690682Z",
     "start_time": "2020-01-03T17:32:02.687046Z"
    }
   },
   "outputs": [],
   "source": [
    "my_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's play with Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Google Playground](https://developers.google.com/machine-learning/crash-course/introduction-to-neural-networks/playground-exercises)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- **Number of Hidden Layers**\n",
    "\n",
    "*For many problems you can start with just one or two hidden layers it will work just fine. For more complex problems, you can gradually ramp up the number of hidden layers until your model starts to over fit. Very complex tasks, like image classification, will need dozens of layers.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Number of Neurons per layer**\n",
    "\n",
    "*The number of nuerons for the input and output layers are dependent on your data and the task. For hiddne layers, a common practice is to create a funnel with funnel with fewer and fewer neurons per layer.*\n",
    "\n",
    "*In general, you will get more bang for your buck by adding on more layers than adding more neurons.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **[Activation Functions](https://towardsdatascience.com/exploring-activation-functions-for-neural-networks-73498da59b02)**\n",
    "    - Linear\n",
    "    - Sigmoid\n",
    "    - Softmax\n",
    "    - Tanh\n",
    "    - ReLu\n",
    "    - elu\n",
    "    \n",
    "*In most cases you can use the ReLu activation function (or one of its variants) in the hidden layers. For the output layer, the softmax activation function is generally good for multiclass problems and the sigmouid function for binary classificatin problems. For regression tasks, you can simply use no activation function at all*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Selecting an optimizer](https://www.dlology.com/blog/quick-notes-on-how-to-choose-optimizer-in-keras/)\n",
    "    - Adam\n",
    "    - SGD\n",
    "    - RMSprop\n",
    "    - Adagrad\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Learning Rate**\n",
    "\n",
    "*If you set it too low, training will eventually converge, but it will do so slowly.*\n",
    "*If you set it too high, it might acutally diverge.*\n",
    "*If you set it slightly too high, it will converge at first but miss the local optima.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Regularization** \n",
    "    - **L1 and L2**\n",
    "    - **Dropout:**\n",
    "        \n",
    "        *Dropout is most popular techniqure for deep neural networks. It is a fairly simple algorithm where at every training step, every neuron has a probability fo being teporarily \"droppedout,\" meaning it will be completely ignored during this traing step, but it may be active during the next step.*\n",
    "    \n",
    "    - [Early Stopping](https://machinelearningmastery.com/how-to-stop-training-deep-neural-networks-at-the-right-time-using-early-stopping/)\n",
    "    \n",
    "    *Just interrupt training whne its performance on the validation set starts dropping*\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Paper on selecting hyperparameters](https://arxiv.org/pdf/1206.5533v2.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitting a Model with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import  Modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T20:17:10.344522Z",
     "start_time": "2020-01-03T20:17:10.341477Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create first network with Keras\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import regularizers\n",
    "from keras.optimizers import SGD\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Model\n",
    "Models in Keras are defined as a sequence of layers.\n",
    "\n",
    "We create a Sequential model and add layers one at a time until we are happy with our network topology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T20:19:39.072256Z",
     "start_time": "2020-01-03T20:19:39.011975Z"
    }
   },
   "outputs": [],
   "source": [
    "network = Sequential()\n",
    "\n",
    "# Add a dropout layer for input layer\n",
    "network.add(Dropout(0.2, input_shape=(n_cols,)))\n",
    "\n",
    "# Add fully connected layer with a ReLU activation function\n",
    "network.add(Dense(units=16, activation='relu'))\n",
    "\n",
    "# Add a dropout layer for previous hidden layer\n",
    "network.add(Dropout(0.25))\n",
    "\n",
    "# Add fully connected layer with a ReLU activation function and L2 regularization\n",
    "network.add(Dense(units=16, kernel_regularizer=regularizers.l2(0.01),activation='relu'))\n",
    "\n",
    "#Final Layer\n",
    "network.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Using GridSearchCV to tune Neural Networks](https://chrisalbon.com/deep_learning/keras/tuning_neural_network_hyperparameters/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T20:20:02.674515Z",
     "start_time": "2020-01-03T20:20:02.629738Z"
    }
   },
   "outputs": [],
   "source": [
    "network.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Keras Implementation of optimizers](https://keras.io/optimizers/)\n",
    "\n",
    "[Impact of Learning Rate on MOdel Performance](https://machinelearningmastery.com/understand-the-dynamics-of-learning-rate-on-deep-learning-neural-networks/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T20:20:03.680456Z",
     "start_time": "2020-01-03T20:20:03.677382Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set callback functions to early stop training and save the best model so far\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=3),\n",
    "             ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T20:20:07.385289Z",
     "start_time": "2020-01-03T20:20:04.770241Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 711 samples, validate on 178 samples\n",
      "Epoch 1/150\n",
      " - 0s - loss: 0.7114 - accuracy: 0.6484 - val_loss: 0.6494 - val_accuracy: 0.6685\n",
      "Epoch 2/150\n",
      " - 0s - loss: 0.6808 - accuracy: 0.6582 - val_loss: 0.6432 - val_accuracy: 0.6910\n",
      "Epoch 3/150\n",
      " - 0s - loss: 0.6864 - accuracy: 0.6639 - val_loss: 0.6483 - val_accuracy: 0.6966\n",
      "Epoch 4/150\n",
      " - 0s - loss: 0.6724 - accuracy: 0.6582 - val_loss: 0.6482 - val_accuracy: 0.6742\n",
      "Epoch 5/150\n",
      " - 0s - loss: 0.6825 - accuracy: 0.6428 - val_loss: 0.6816 - val_accuracy: 0.6124\n",
      "Epoch 6/150\n",
      " - 0s - loss: 0.6765 - accuracy: 0.6498 - val_loss: 0.6696 - val_accuracy: 0.6124\n",
      "Epoch 7/150\n",
      " - 0s - loss: 0.6888 - accuracy: 0.6484 - val_loss: 0.6443 - val_accuracy: 0.6966\n",
      "Epoch 8/150\n",
      " - 0s - loss: 0.6881 - accuracy: 0.6582 - val_loss: 0.6394 - val_accuracy: 0.6966\n",
      "Epoch 9/150\n",
      " - 0s - loss: 0.6794 - accuracy: 0.6582 - val_loss: 0.6604 - val_accuracy: 0.6629\n",
      "Epoch 10/150\n",
      " - 0s - loss: 0.6820 - accuracy: 0.6484 - val_loss: 0.6344 - val_accuracy: 0.6910\n",
      "Epoch 11/150\n",
      " - 0s - loss: 0.6870 - accuracy: 0.6484 - val_loss: 0.7843 - val_accuracy: 0.6124\n",
      "Epoch 12/150\n",
      " - 0s - loss: 0.6844 - accuracy: 0.6428 - val_loss: 0.6426 - val_accuracy: 0.6966\n",
      "Epoch 13/150\n",
      " - 0s - loss: 0.6787 - accuracy: 0.6554 - val_loss: 0.6373 - val_accuracy: 0.6798\n",
      "Epoch 14/150\n",
      " - 0s - loss: 0.6783 - accuracy: 0.6568 - val_loss: 0.6342 - val_accuracy: 0.7079\n",
      "Epoch 15/150\n",
      " - 0s - loss: 0.6754 - accuracy: 0.6554 - val_loss: 0.6319 - val_accuracy: 0.6910\n",
      "Epoch 16/150\n",
      " - 0s - loss: 0.6669 - accuracy: 0.6470 - val_loss: 0.6595 - val_accuracy: 0.6685\n",
      "Epoch 17/150\n",
      " - 0s - loss: 0.6708 - accuracy: 0.6526 - val_loss: 0.6311 - val_accuracy: 0.6910\n",
      "Epoch 18/150\n",
      " - 0s - loss: 0.6780 - accuracy: 0.6456 - val_loss: 0.6435 - val_accuracy: 0.6685\n",
      "Epoch 19/150\n",
      " - 0s - loss: 0.6870 - accuracy: 0.6484 - val_loss: 0.6867 - val_accuracy: 0.6180\n",
      "Epoch 20/150\n",
      " - 0s - loss: 0.6949 - accuracy: 0.6428 - val_loss: 0.6700 - val_accuracy: 0.6124\n",
      "Epoch 21/150\n",
      " - 0s - loss: 0.6778 - accuracy: 0.6498 - val_loss: 0.6346 - val_accuracy: 0.6966\n",
      "Epoch 22/150\n",
      " - 0s - loss: 0.6841 - accuracy: 0.6371 - val_loss: 0.6444 - val_accuracy: 0.6798\n",
      "Epoch 23/150\n",
      " - 0s - loss: 0.6649 - accuracy: 0.6610 - val_loss: 0.6297 - val_accuracy: 0.6966\n",
      "Epoch 24/150\n",
      " - 0s - loss: 0.6703 - accuracy: 0.6484 - val_loss: 0.6381 - val_accuracy: 0.7135\n",
      "Epoch 25/150\n",
      " - 0s - loss: 0.6662 - accuracy: 0.6554 - val_loss: 0.6650 - val_accuracy: 0.6461\n",
      "Epoch 26/150\n",
      " - 0s - loss: 0.6663 - accuracy: 0.6554 - val_loss: 0.7968 - val_accuracy: 0.6124\n",
      "Epoch 27/150\n",
      " - 0s - loss: 0.7046 - accuracy: 0.6329 - val_loss: 0.6429 - val_accuracy: 0.6742\n",
      "Epoch 28/150\n",
      " - 0s - loss: 0.6836 - accuracy: 0.6512 - val_loss: 0.6604 - val_accuracy: 0.6348\n",
      "Epoch 29/150\n",
      " - 0s - loss: 0.6444 - accuracy: 0.6695 - val_loss: 0.6331 - val_accuracy: 0.7079\n",
      "Epoch 30/150\n",
      " - 0s - loss: 0.6556 - accuracy: 0.6653 - val_loss: 0.6632 - val_accuracy: 0.6236\n",
      "Epoch 31/150\n",
      " - 0s - loss: 0.6685 - accuracy: 0.6385 - val_loss: 0.6300 - val_accuracy: 0.6966\n",
      "Epoch 32/150\n",
      " - 0s - loss: 0.6649 - accuracy: 0.6596 - val_loss: 0.6580 - val_accuracy: 0.6180\n",
      "Epoch 33/150\n",
      " - 0s - loss: 0.6650 - accuracy: 0.6723 - val_loss: 0.6265 - val_accuracy: 0.6910\n",
      "Epoch 34/150\n",
      " - 0s - loss: 0.6748 - accuracy: 0.6498 - val_loss: 0.6274 - val_accuracy: 0.7022\n",
      "Epoch 35/150\n",
      " - 0s - loss: 0.6741 - accuracy: 0.6512 - val_loss: 0.6698 - val_accuracy: 0.6348\n",
      "Epoch 36/150\n",
      " - 0s - loss: 0.6742 - accuracy: 0.6456 - val_loss: 0.6508 - val_accuracy: 0.6854\n",
      "Epoch 37/150\n",
      " - 0s - loss: 0.6819 - accuracy: 0.6568 - val_loss: 0.6296 - val_accuracy: 0.7079\n",
      "Epoch 38/150\n",
      " - 0s - loss: 0.6626 - accuracy: 0.6765 - val_loss: 0.6436 - val_accuracy: 0.7022\n",
      "Epoch 39/150\n",
      " - 0s - loss: 0.6811 - accuracy: 0.6484 - val_loss: 0.6342 - val_accuracy: 0.6854\n",
      "Epoch 40/150\n",
      " - 0s - loss: 0.6440 - accuracy: 0.6751 - val_loss: 0.7027 - val_accuracy: 0.6124\n",
      "Epoch 41/150\n",
      " - 0s - loss: 0.6738 - accuracy: 0.6540 - val_loss: 0.6290 - val_accuracy: 0.6966\n",
      "Epoch 42/150\n",
      " - 0s - loss: 0.6743 - accuracy: 0.6484 - val_loss: 0.6377 - val_accuracy: 0.6742\n",
      "Epoch 43/150\n",
      " - 0s - loss: 0.6571 - accuracy: 0.6850 - val_loss: 0.6395 - val_accuracy: 0.6910\n",
      "Epoch 44/150\n",
      " - 0s - loss: 0.6797 - accuracy: 0.6498 - val_loss: 0.6684 - val_accuracy: 0.6124\n",
      "Epoch 45/150\n",
      " - 0s - loss: 0.6689 - accuracy: 0.6484 - val_loss: 0.6356 - val_accuracy: 0.6517\n",
      "Epoch 46/150\n",
      " - 0s - loss: 0.6656 - accuracy: 0.6442 - val_loss: 0.6431 - val_accuracy: 0.7135\n",
      "Epoch 47/150\n",
      " - 0s - loss: 0.6779 - accuracy: 0.6554 - val_loss: 0.6246 - val_accuracy: 0.7135\n",
      "Epoch 48/150\n",
      " - 0s - loss: 0.6541 - accuracy: 0.6582 - val_loss: 0.6546 - val_accuracy: 0.6180\n",
      "Epoch 49/150\n",
      " - 0s - loss: 0.6470 - accuracy: 0.6414 - val_loss: 0.7359 - val_accuracy: 0.6124\n",
      "Epoch 50/150\n",
      " - 0s - loss: 0.6836 - accuracy: 0.6470 - val_loss: 0.6261 - val_accuracy: 0.6966\n",
      "Epoch 51/150\n",
      " - 0s - loss: 0.6552 - accuracy: 0.6779 - val_loss: 0.6480 - val_accuracy: 0.6292\n",
      "Epoch 52/150\n",
      " - 0s - loss: 0.6652 - accuracy: 0.6371 - val_loss: 0.6187 - val_accuracy: 0.6966\n",
      "Epoch 53/150\n",
      " - 0s - loss: 0.6627 - accuracy: 0.6667 - val_loss: 0.6295 - val_accuracy: 0.7022\n",
      "Epoch 54/150\n",
      " - 0s - loss: 0.6643 - accuracy: 0.6582 - val_loss: 0.6266 - val_accuracy: 0.6966\n",
      "Epoch 55/150\n",
      " - 0s - loss: 0.6564 - accuracy: 0.6512 - val_loss: 0.6160 - val_accuracy: 0.7079\n",
      "Epoch 56/150\n",
      " - 0s - loss: 0.6628 - accuracy: 0.6624 - val_loss: 0.6716 - val_accuracy: 0.6124\n",
      "Epoch 57/150\n",
      " - 0s - loss: 0.6568 - accuracy: 0.6470 - val_loss: 0.6229 - val_accuracy: 0.6910\n",
      "Epoch 58/150\n",
      " - 0s - loss: 0.6597 - accuracy: 0.6639 - val_loss: 0.6207 - val_accuracy: 0.7135\n",
      "Epoch 59/150\n",
      " - 0s - loss: 0.6566 - accuracy: 0.6540 - val_loss: 0.6383 - val_accuracy: 0.6854\n",
      "Epoch 60/150\n",
      " - 0s - loss: 0.6431 - accuracy: 0.6596 - val_loss: 0.6234 - val_accuracy: 0.6966\n",
      "Epoch 61/150\n",
      " - 0s - loss: 0.6667 - accuracy: 0.6624 - val_loss: 0.6255 - val_accuracy: 0.7022\n",
      "Epoch 62/150\n",
      " - 0s - loss: 0.6582 - accuracy: 0.6484 - val_loss: 0.6290 - val_accuracy: 0.6966\n",
      "Epoch 63/150\n",
      " - 0s - loss: 0.6444 - accuracy: 0.6807 - val_loss: 0.6670 - val_accuracy: 0.6124\n",
      "Epoch 64/150\n",
      " - 0s - loss: 0.6633 - accuracy: 0.6624 - val_loss: 0.6283 - val_accuracy: 0.6910\n",
      "Epoch 65/150\n",
      " - 0s - loss: 0.6751 - accuracy: 0.6681 - val_loss: 0.6143 - val_accuracy: 0.6966\n",
      "Epoch 66/150\n",
      " - 0s - loss: 0.6555 - accuracy: 0.6414 - val_loss: 0.6541 - val_accuracy: 0.6180\n",
      "Epoch 67/150\n",
      " - 0s - loss: 0.6452 - accuracy: 0.6681 - val_loss: 0.6278 - val_accuracy: 0.6573\n",
      "Epoch 68/150\n",
      " - 0s - loss: 0.6542 - accuracy: 0.6667 - val_loss: 0.6190 - val_accuracy: 0.6854\n",
      "Epoch 69/150\n",
      " - 0s - loss: 0.6496 - accuracy: 0.6512 - val_loss: 0.6168 - val_accuracy: 0.6910\n",
      "Epoch 70/150\n",
      " - 0s - loss: 0.6569 - accuracy: 0.6596 - val_loss: 0.6167 - val_accuracy: 0.7135\n",
      "Epoch 71/150\n",
      " - 0s - loss: 0.6538 - accuracy: 0.6737 - val_loss: 0.6310 - val_accuracy: 0.6292\n",
      "Epoch 72/150\n",
      " - 0s - loss: 0.6464 - accuracy: 0.6779 - val_loss: 0.6471 - val_accuracy: 0.6180\n",
      "Epoch 73/150\n",
      " - 0s - loss: 0.6567 - accuracy: 0.6568 - val_loss: 0.6216 - val_accuracy: 0.7135\n",
      "Epoch 74/150\n",
      " - 0s - loss: 0.6634 - accuracy: 0.6498 - val_loss: 0.6256 - val_accuracy: 0.7022\n",
      "Epoch 75/150\n",
      " - 0s - loss: 0.6341 - accuracy: 0.6765 - val_loss: 0.6111 - val_accuracy: 0.7022\n",
      "Epoch 76/150\n",
      " - 0s - loss: 0.6664 - accuracy: 0.6653 - val_loss: 0.6346 - val_accuracy: 0.6798\n",
      "Epoch 77/150\n",
      " - 0s - loss: 0.6525 - accuracy: 0.6667 - val_loss: 0.6167 - val_accuracy: 0.7191\n",
      "Epoch 78/150\n",
      " - 0s - loss: 0.6565 - accuracy: 0.6442 - val_loss: 0.6191 - val_accuracy: 0.7022\n",
      "Epoch 79/150\n",
      " - 0s - loss: 0.6291 - accuracy: 0.6892 - val_loss: 0.6111 - val_accuracy: 0.7303\n",
      "Epoch 80/150\n",
      " - 0s - loss: 0.6654 - accuracy: 0.6540 - val_loss: 0.6137 - val_accuracy: 0.6910\n",
      "Epoch 81/150\n",
      " - 0s - loss: 0.6474 - accuracy: 0.6667 - val_loss: 0.6117 - val_accuracy: 0.6966\n",
      "Epoch 82/150\n",
      " - 0s - loss: 0.6524 - accuracy: 0.6667 - val_loss: 0.6207 - val_accuracy: 0.6798\n",
      "Epoch 83/150\n",
      " - 0s - loss: 0.6516 - accuracy: 0.6751 - val_loss: 0.6098 - val_accuracy: 0.7022\n",
      "Epoch 84/150\n",
      " - 0s - loss: 0.6563 - accuracy: 0.6470 - val_loss: 0.6800 - val_accuracy: 0.6124\n",
      "Epoch 85/150\n",
      " - 0s - loss: 0.6590 - accuracy: 0.6681 - val_loss: 0.6182 - val_accuracy: 0.7022\n",
      "Epoch 86/150\n",
      " - 0s - loss: 0.6472 - accuracy: 0.6596 - val_loss: 0.6507 - val_accuracy: 0.6124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/150\n",
      " - 0s - loss: 0.6528 - accuracy: 0.6681 - val_loss: 0.6114 - val_accuracy: 0.7022\n",
      "Epoch 88/150\n",
      " - 0s - loss: 0.6433 - accuracy: 0.6653 - val_loss: 0.6442 - val_accuracy: 0.6236\n",
      "Epoch 89/150\n",
      " - 0s - loss: 0.6540 - accuracy: 0.6596 - val_loss: 0.6195 - val_accuracy: 0.6910\n",
      "Epoch 90/150\n",
      " - 0s - loss: 0.6413 - accuracy: 0.6512 - val_loss: 0.6901 - val_accuracy: 0.6124\n",
      "Epoch 91/150\n",
      " - 0s - loss: 0.6509 - accuracy: 0.6540 - val_loss: 0.6038 - val_accuracy: 0.7303\n",
      "Epoch 92/150\n",
      " - 0s - loss: 0.6444 - accuracy: 0.6695 - val_loss: 0.6115 - val_accuracy: 0.7022\n",
      "Epoch 93/150\n",
      " - 0s - loss: 0.6523 - accuracy: 0.6568 - val_loss: 0.6062 - val_accuracy: 0.7079\n",
      "Epoch 94/150\n",
      " - 0s - loss: 0.6472 - accuracy: 0.6807 - val_loss: 0.6330 - val_accuracy: 0.6348\n",
      "Epoch 95/150\n",
      " - 0s - loss: 0.6381 - accuracy: 0.6512 - val_loss: 0.6212 - val_accuracy: 0.6966\n",
      "Epoch 96/150\n",
      " - 0s - loss: 0.6494 - accuracy: 0.6624 - val_loss: 0.6112 - val_accuracy: 0.6966\n",
      "Epoch 97/150\n",
      " - 0s - loss: 0.6549 - accuracy: 0.6723 - val_loss: 0.6243 - val_accuracy: 0.6573\n",
      "Epoch 98/150\n",
      " - 0s - loss: 0.6543 - accuracy: 0.6596 - val_loss: 0.6145 - val_accuracy: 0.6966\n",
      "Epoch 99/150\n",
      " - 0s - loss: 0.6372 - accuracy: 0.6779 - val_loss: 0.6063 - val_accuracy: 0.7079\n",
      "Epoch 100/150\n",
      " - 0s - loss: 0.6462 - accuracy: 0.6737 - val_loss: 0.5990 - val_accuracy: 0.7360\n",
      "Epoch 101/150\n",
      " - 0s - loss: 0.6391 - accuracy: 0.6624 - val_loss: 0.6045 - val_accuracy: 0.7360\n",
      "Epoch 102/150\n",
      " - 0s - loss: 0.6448 - accuracy: 0.6835 - val_loss: 0.6001 - val_accuracy: 0.7079\n",
      "Epoch 103/150\n",
      " - 0s - loss: 0.6265 - accuracy: 0.6864 - val_loss: 0.6570 - val_accuracy: 0.6124\n",
      "Epoch 104/150\n",
      " - 0s - loss: 0.6322 - accuracy: 0.6568 - val_loss: 0.6205 - val_accuracy: 0.6404\n",
      "Epoch 105/150\n",
      " - 0s - loss: 0.6455 - accuracy: 0.6610 - val_loss: 0.6825 - val_accuracy: 0.6124\n",
      "Epoch 106/150\n",
      " - 0s - loss: 0.6631 - accuracy: 0.6512 - val_loss: 0.6197 - val_accuracy: 0.6461\n",
      "Epoch 107/150\n",
      " - 0s - loss: 0.6482 - accuracy: 0.6596 - val_loss: 0.6245 - val_accuracy: 0.6348\n",
      "Epoch 108/150\n",
      " - 0s - loss: 0.6467 - accuracy: 0.6835 - val_loss: 0.6147 - val_accuracy: 0.6573\n",
      "Epoch 109/150\n",
      " - 0s - loss: 0.6439 - accuracy: 0.6667 - val_loss: 0.6538 - val_accuracy: 0.6124\n",
      "Epoch 110/150\n",
      " - 0s - loss: 0.6488 - accuracy: 0.6610 - val_loss: 0.6042 - val_accuracy: 0.7247\n",
      "Epoch 111/150\n",
      " - 0s - loss: 0.6310 - accuracy: 0.6850 - val_loss: 0.6183 - val_accuracy: 0.6629\n",
      "Epoch 112/150\n",
      " - 0s - loss: 0.6458 - accuracy: 0.6610 - val_loss: 0.5957 - val_accuracy: 0.7135\n",
      "Epoch 113/150\n",
      " - 0s - loss: 0.6414 - accuracy: 0.6765 - val_loss: 0.6602 - val_accuracy: 0.6124\n",
      "Epoch 114/150\n",
      " - 0s - loss: 0.6590 - accuracy: 0.6667 - val_loss: 0.6095 - val_accuracy: 0.6966\n",
      "Epoch 115/150\n",
      " - 0s - loss: 0.6166 - accuracy: 0.6807 - val_loss: 0.6480 - val_accuracy: 0.7303\n",
      "Epoch 116/150\n",
      " - 0s - loss: 0.6431 - accuracy: 0.6765 - val_loss: 0.6064 - val_accuracy: 0.7247\n",
      "Epoch 117/150\n",
      " - 0s - loss: 0.6570 - accuracy: 0.6709 - val_loss: 0.6101 - val_accuracy: 0.6910\n",
      "Epoch 118/150\n",
      " - 0s - loss: 0.6336 - accuracy: 0.6934 - val_loss: 0.6144 - val_accuracy: 0.6461\n",
      "Epoch 119/150\n",
      " - 0s - loss: 0.6210 - accuracy: 0.7159 - val_loss: 0.5958 - val_accuracy: 0.7135\n",
      "Epoch 120/150\n",
      " - 0s - loss: 0.6474 - accuracy: 0.6639 - val_loss: 0.6214 - val_accuracy: 0.6067\n",
      "Epoch 121/150\n",
      " - 0s - loss: 0.6504 - accuracy: 0.6526 - val_loss: 0.5964 - val_accuracy: 0.7135\n",
      "Epoch 122/150\n",
      " - 0s - loss: 0.6454 - accuracy: 0.6695 - val_loss: 0.5923 - val_accuracy: 0.7079\n",
      "Epoch 123/150\n",
      " - 0s - loss: 0.6355 - accuracy: 0.6779 - val_loss: 0.6189 - val_accuracy: 0.7135\n",
      "Epoch 124/150\n",
      " - 0s - loss: 0.6263 - accuracy: 0.6864 - val_loss: 0.5940 - val_accuracy: 0.7303\n",
      "Epoch 125/150\n",
      " - 0s - loss: 0.6302 - accuracy: 0.6807 - val_loss: 0.5928 - val_accuracy: 0.7022\n",
      "Epoch 126/150\n",
      " - 0s - loss: 0.6244 - accuracy: 0.6920 - val_loss: 0.6028 - val_accuracy: 0.7247\n",
      "Epoch 127/150\n",
      " - 0s - loss: 0.6370 - accuracy: 0.6751 - val_loss: 0.6023 - val_accuracy: 0.7247\n",
      "Epoch 128/150\n",
      " - 0s - loss: 0.6314 - accuracy: 0.6723 - val_loss: 0.6217 - val_accuracy: 0.6461\n",
      "Epoch 129/150\n",
      " - 0s - loss: 0.6401 - accuracy: 0.6639 - val_loss: 0.5992 - val_accuracy: 0.7135\n",
      "Epoch 130/150\n",
      " - 0s - loss: 0.6434 - accuracy: 0.6639 - val_loss: 0.5884 - val_accuracy: 0.7360\n",
      "Epoch 131/150\n",
      " - 0s - loss: 0.6140 - accuracy: 0.6821 - val_loss: 0.5882 - val_accuracy: 0.7135\n",
      "Epoch 132/150\n",
      " - 0s - loss: 0.6443 - accuracy: 0.6695 - val_loss: 0.5877 - val_accuracy: 0.7247\n",
      "Epoch 133/150\n",
      " - 0s - loss: 0.6284 - accuracy: 0.6864 - val_loss: 0.6052 - val_accuracy: 0.6910\n",
      "Epoch 134/150\n",
      " - 0s - loss: 0.6545 - accuracy: 0.6610 - val_loss: 0.5995 - val_accuracy: 0.7079\n",
      "Epoch 135/150\n",
      " - 0s - loss: 0.6434 - accuracy: 0.6751 - val_loss: 0.6090 - val_accuracy: 0.6798\n",
      "Epoch 136/150\n",
      " - 0s - loss: 0.6423 - accuracy: 0.6906 - val_loss: 0.5825 - val_accuracy: 0.7360\n",
      "Epoch 137/150\n",
      " - 0s - loss: 0.6347 - accuracy: 0.6807 - val_loss: 0.5817 - val_accuracy: 0.7022\n",
      "Epoch 138/150\n",
      " - 0s - loss: 0.6134 - accuracy: 0.6821 - val_loss: 0.5965 - val_accuracy: 0.7191\n",
      "Epoch 139/150\n",
      " - 0s - loss: 0.6323 - accuracy: 0.6821 - val_loss: 0.5903 - val_accuracy: 0.7135\n",
      "Epoch 140/150\n",
      " - 0s - loss: 0.6449 - accuracy: 0.6723 - val_loss: 0.5905 - val_accuracy: 0.7079\n",
      "Epoch 141/150\n",
      " - 0s - loss: 0.6245 - accuracy: 0.6976 - val_loss: 0.5947 - val_accuracy: 0.7303\n",
      "Epoch 142/150\n",
      " - 0s - loss: 0.6435 - accuracy: 0.6737 - val_loss: 0.6156 - val_accuracy: 0.6011\n",
      "Epoch 143/150\n",
      " - 0s - loss: 0.6337 - accuracy: 0.6709 - val_loss: 0.5876 - val_accuracy: 0.7303\n",
      "Epoch 144/150\n",
      " - 0s - loss: 0.6225 - accuracy: 0.6948 - val_loss: 0.6290 - val_accuracy: 0.6067\n",
      "Epoch 145/150\n",
      " - 0s - loss: 0.6403 - accuracy: 0.6793 - val_loss: 0.5793 - val_accuracy: 0.7472\n",
      "Epoch 146/150\n",
      " - 0s - loss: 0.6157 - accuracy: 0.7018 - val_loss: 0.6201 - val_accuracy: 0.6404\n",
      "Epoch 147/150\n",
      " - 0s - loss: 0.6333 - accuracy: 0.6568 - val_loss: 0.5863 - val_accuracy: 0.7472\n",
      "Epoch 148/150\n",
      " - 0s - loss: 0.6133 - accuracy: 0.6765 - val_loss: 0.5822 - val_accuracy: 0.7360\n",
      "Epoch 149/150\n",
      " - 0s - loss: 0.6232 - accuracy: 0.6850 - val_loss: 0.5800 - val_accuracy: 0.7472\n",
      "Epoch 150/150\n",
      " - 0s - loss: 0.6272 - accuracy: 0.6723 - val_loss: 0.5759 - val_accuracy: 0.7135\n"
     ]
    }
   ],
   "source": [
    "# Train neural network\n",
    "history = network.fit(X_train, # Features\n",
    "                      y_train, # Target\n",
    "                      epochs=150, # Number of epochs\n",
    "                      verbose=2, # Some output\n",
    "                      batch_size=100, # Number of observations per batch\n",
    "                      validation_data=(X_test, y_test)) # Data for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T17:32:15.849934Z",
     "start_time": "2020-01-03T17:32:15.846118Z"
    }
   },
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T17:32:17.003459Z",
     "start_time": "2020-01-03T17:32:16.994965Z"
    }
   },
   "outputs": [],
   "source": [
    "score = network.evaluate(X_test, y_test, batch_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T17:32:17.567160Z",
     "start_time": "2020-01-03T17:32:17.563535Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"\\n%s: %.2f%%\" % (network.metrics_names[1], score[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T17:32:18.883814Z",
     "start_time": "2020-01-03T17:32:18.829935Z"
    }
   },
   "outputs": [],
   "source": [
    "# calculate predictions\n",
    "predictions = network.predict(X_test)\n",
    "# round predictions\n",
    "rounded = [round(x[0]) for x in predictions]\n",
    "print(rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T17:32:19.607239Z",
     "start_time": "2020-01-03T17:32:19.423222Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get training and test loss histories\n",
    "training_loss = history.history['loss']\n",
    "test_loss = history.history['val_loss']\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(training_loss) + 1)\n",
    "\n",
    "# Visualize loss history\n",
    "plt.plot(epoch_count, training_loss, 'r--')\n",
    "plt.plot(epoch_count, test_loss, 'b-')\n",
    "plt.legend(['Training Loss', 'Test Loss'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://chrisalbon.com/deep_learning/keras/visualize_loss_history/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T17:33:16.744250Z",
     "start_time": "2020-01-03T17:33:16.582454Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get training and test accuracy histories\n",
    "training_accuracy = history.history['accuracy']\n",
    "test_accuracy = history.history['val_accuracy']\n",
    "\n",
    "# Create count of the number of epochs\n",
    "epoch_count = range(1, len(training_accuracy) + 1)\n",
    "\n",
    "# Visualize accuracy history\n",
    "plt.plot(epoch_count, training_accuracy, 'r--')\n",
    "plt.plot(epoch_count, test_accuracy, 'b-')\n",
    "plt.legend(['Training Accuracy', 'Test Accuracy'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://chrisalbon.com/deep_learning/keras/visualize_performance_history/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T17:34:22.568870Z",
     "start_time": "2020-01-03T17:34:22.548296Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# calculate predictions\n",
    "predictions = model.predict(X)\n",
    "# round predictions\n",
    "rounded = [round(x[0]) for x in predictions]\n",
    "print(rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-03T17:32:42.515041Z",
     "start_time": "2020-01-03T17:32:42.510676Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'val_loss': [2.4037557023294855,\n",
       "  1.8078752635570055,\n",
       "  1.474654642383704,\n",
       "  1.1593707210562203,\n",
       "  0.8798026516196433,\n",
       "  0.7952060190479407,\n",
       "  0.7757672600531846,\n",
       "  0.7737625984663374,\n",
       "  0.7732174530457915,\n",
       "  0.8081348223632641,\n",
       "  0.8013650607526972,\n",
       "  0.7614630688442273,\n",
       "  0.7903076483962241,\n",
       "  0.7847130111094271,\n",
       "  0.7326249165481395],\n",
       " 'val_accuracy': [0.6067415475845337,\n",
       "  0.5393258333206177,\n",
       "  0.516853928565979,\n",
       "  0.567415714263916,\n",
       "  0.5955055952072144,\n",
       "  0.6741573214530945,\n",
       "  0.6741573214530945,\n",
       "  0.6741573214530945,\n",
       "  0.6516854166984558,\n",
       "  0.6292135119438171,\n",
       "  0.6123595237731934,\n",
       "  0.6123595237731934,\n",
       "  0.6123595237731934,\n",
       "  0.601123571395874,\n",
       "  0.6573033928871155],\n",
       " 'loss': [2.595739585605519,\n",
       "  2.301990841846761,\n",
       "  2.114603793738428,\n",
       "  1.869537460150095,\n",
       "  1.6885028936691928,\n",
       "  1.648949906460511,\n",
       "  1.6461859949865758,\n",
       "  1.3675116416271227,\n",
       "  1.3834792554965334,\n",
       "  1.471722950915244,\n",
       "  1.3954162889392063,\n",
       "  1.2058487374403641,\n",
       "  1.3378643864653115,\n",
       "  1.2267961823990576,\n",
       "  1.0508578487589388],\n",
       " 'accuracy': [0.6026723,\n",
       "  0.5499297,\n",
       "  0.5049226,\n",
       "  0.5288326,\n",
       "  0.5443038,\n",
       "  0.5541491,\n",
       "  0.54008436,\n",
       "  0.54149085,\n",
       "  0.5583685,\n",
       "  0.53727144,\n",
       "  0.53727144,\n",
       "  0.5583685,\n",
       "  0.51476794,\n",
       "  0.5232068,\n",
       "  0.61603373]}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources \n",
    "\n",
    "http://neuralnetworksanddeeplearning.com/\n",
    "    \n",
    "http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/\n",
    "\n",
    "https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://chrisalbon.com/deep_learning/keras/visualize_neural_network_architecture/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
